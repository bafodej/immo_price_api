{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "694aaf40",
   "metadata": {},
   "source": [
    "# Modélisation du prix du m² à lille (année2022) pour les logements de 4 pièces, Séparation appartements vs maisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11025e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9adeb33",
   "metadata": {},
   "source": [
    "## Chargement , exploration et vérification des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d08b5c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chargement des données de Lille...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/lille_2022.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Appel de  la fonction pour charger et explorer les données\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m df = \u001b[43mload_and_explore_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mload_and_explore_data\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" Charger les données de Lille\"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m Chargement des données de Lille...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/lille_2022.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Données chargées : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m transactions\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Explorer les colonnes disponibles\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/immo_price_api/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/immo_price_api/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/immo_price_api/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/immo_price_api/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/immo_price_api/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/lille_2022.csv'"
     ]
    }
   ],
   "source": [
    "# Configuration des graphiques\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "def load_and_explore_data():\n",
    "    \"\"\" Charger les données de Lille\"\"\"\n",
    "    print(\" Chargement des données de Lille...\")\n",
    "    \n",
    "    df = pd.read_csv(\"../data/lille_2022.csv\")\n",
    "    print(f\" Données chargées : {len(df)} transactions\")\n",
    "    \n",
    "    # Explorer les colonnes disponibles\n",
    "    print(\" Colonnes disponibles :\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "    \n",
    "    # Vérifier les types de logements\n",
    "    if 'Type local' in df.columns:\n",
    "        print(f\" Types de logements :\")\n",
    "        print(df['Type local'].value_counts())\n",
    "    \n",
    "    # Vérifier les nombres de pièces\n",
    "    if 'Nombre pieces principales' in df.columns:\n",
    "        print(f\" Répartition nombre de pièces :\")\n",
    "        print(df['Nombre pieces principales'].value_counts().sort_index())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Appel de  la fonction pour charger et explorer les données\n",
    "df = load_and_explore_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18695b94",
   "metadata": {},
   "source": [
    "## Filtrage des logements 4 pièces ,séparation maisons / appartements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45188997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_4_pieces_data(df):\n",
    "    \"\"\" Filtrer les logements de 4 pièces\"\"\"\n",
    "    print(\" Filtrage des logements 4 pièces...\")\n",
    "    \n",
    "    # Filtrer les 4 pièces\n",
    "    df_4p = df[df['Nombre pieces principales'] == 4].copy()\n",
    "    print(f\" Logements 4 pièces : {len(df_4p)} transactions\")\n",
    "    \n",
    "    if len(df_4p) == 0:\n",
    "        print(\" Aucun logement 4 pièces trouvé !\")\n",
    "        return None, None\n",
    "    \n",
    "    # Vérifier les types de logements dans les 4 pièces\n",
    "    print(f\" Types de logements 4 pièces :\")\n",
    "    print(df_4p['Type local'].value_counts())\n",
    "    \n",
    "    return(df_4p)\n",
    "    #appel de la fonction\n",
    "df_4p = filter_4_pieces_data(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "#Créer les variables\n",
    "appartements = df_4p[df_4p['Type local'] == 'Appartement'].copy()\n",
    "maisons = df_4p[df_4p['Type local'] == 'Maison'].copy()\n",
    "\n",
    "print(f\" Appartements 4 pièces : {len(appartements)}\")\n",
    "print(f\" Maisons 4 pièces : {len(maisons)}\")\n",
    "\n",
    "#   Définir la fonction de nettoyage\n",
    "def select_features_and_clean(df, dataset_name):\n",
    "    \"\"\"Sélectionner les colonnes et nettoyer\"\"\"\n",
    "    print(f\" Nettoyage données {dataset_name}...\")\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        print(f\" Aucune donnée pour {dataset_name}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Colonnes à conserver\n",
    "    required_cols = ['Surface reelle bati', 'Nombre pieces principales', 'Type local', 'Valeur fonciere']\n",
    "    optional_cols = ['Surface terrain', 'Nombre de lots']\n",
    "    \n",
    "    # Vérifier colonnes disponibles\n",
    "    available_cols = [col for col in required_cols if col in df.columns]\n",
    "    available_optional = [col for col in optional_cols if col in df.columns]\n",
    "    \n",
    "    print(f\" Colonnes disponibles : {available_cols + available_optional}\")\n",
    "    \n",
    "    # Sélectionner et nettoyer\n",
    "    selected_cols = available_cols + available_optional\n",
    "    df_clean = df[selected_cols].copy()\n",
    "    \n",
    "    # Créer prix_m2 (Variable cible)\n",
    "    df_clean['prix_m2'] = df_clean['Valeur fonciere'] / df_clean['Surface reelle bati']\n",
    "    print(f\" Variable prix_m2 créée\")\n",
    "    \n",
    "    # Nettoyage\n",
    "    print(f\" Avant nettoyage : {len(df_clean)} lignes\")\n",
    "    \n",
    "    # Remplacer valeurs manquantes \n",
    "    if 'Surface terrain' in df_clean.columns:\n",
    "        df_clean['Surface terrain'] = df_clean['Surface terrain'].fillna(0)\n",
    "    if 'Nombre de lots' in df_clean.columns:\n",
    "        df_clean['Nombre de lots'] = df_clean['Nombre de lots'].fillna(1)\n",
    "    \n",
    "    # Supprimer lignes avec données essentielles manquantes\n",
    "    df_clean = df_clean.dropna(subset=['Surface reelle bati', 'Valeur fonciere'])\n",
    "    print(f\" Après nettoyage valeurs manquantes : {len(df_clean)} lignes\")\n",
    "    \n",
    "    # Identifier et retirer les valeurs aberrantes (prix au m²)\n",
    "    if len(df_clean) > 0:\n",
    "        Q1 = df_clean['prix_m2'].quantile(0.25)\n",
    "        Q3 = df_clean['prix_m2'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Limites pour les outliers\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        print(f\" Détection outliers prix_m2 :\")\n",
    "        print(f\"   Q1: {Q1:.2f}, Q3: {Q3:.2f}\")\n",
    "        print(f\"   Limites: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "        \n",
    "        # Filtrer les outliers\n",
    "        mask = (df_clean['prix_m2'] >= lower_bound) & (df_clean['prix_m2'] <= upper_bound)\n",
    "        df_clean = df_clean[mask]\n",
    "        \n",
    "        print(f\" Après suppression outliers : {len(df_clean)} lignes\")\n",
    "    \n",
    "    if len(df_clean) == 0:\n",
    "        print(f\" Plus de données après nettoyage pour {dataset_name}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Préparer X et y\n",
    "    feature_cols = [col for col in df_clean.columns if col not in ['Valeur fonciere', 'prix_m2', 'Type local']]\n",
    "    X = df_clean[feature_cols]\n",
    "    y = df_clean['prix_m2']\n",
    "        \n",
    "    # Afficher quelques statistiques\n",
    "    print(f\"  Statistiques {dataset_name} :\")\n",
    "    print(f\"  Prix m² min: {df_clean['prix_m2'].min():.2f} €\")\n",
    "    print(f\"  Prix m² max: {df_clean['prix_m2'].max():.2f} €\")\n",
    "    print(f\"  Prix m² moyen: {df_clean['prix_m2'].mean():.2f} €\")\n",
    "    print(f\"  Variables : {list(X.columns)}\")\n",
    "    \n",
    "    return X, y, df_clean\n",
    "\n",
    "# Appeler la fonction\n",
    "print(\"\\n=== NETTOYAGE APPARTEMENTS ===\")\n",
    "X_apt, y_apt, df_apt_clean = select_features_and_clean(appartements, \"APPARTEMENTS\")\n",
    "\n",
    "print(\"\\n=== NETTOYAGE MAISONS ===\")\n",
    "X_maisons, y_maisons, df_maisons_clean = select_features_and_clean(maisons, \"MAISONS\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63b7431",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exploration des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee36fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer les distributions de prix\n",
    "if df_apt_clean is not None and df_maisons_clean is not None:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(df_apt_clean['prix_m2'], bins=30, alpha=0.7, label='Appartements')\n",
    "    plt.hist(df_maisons_clean['prix_m2'], bins=30, alpha=0.7, label='Maisons')\n",
    "    plt.xlabel('Prix au m² (€)')\n",
    "    plt.ylabel('Fréquence')\n",
    "    plt.title('Distribution des prix au m²')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.boxplot([df_apt_clean['prix_m2'], df_maisons_clean['prix_m2']], \n",
    "                label=['Appartements', 'Maisons'])\n",
    "    plt.ylabel('Prix au m² (€)')\n",
    "    plt.title('Comparaison des prix par type')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d11054",
   "metadata": {},
   "source": [
    "## Division en jeu d'entraînement (80%) et test (20%) avec train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cfaec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Division train/test \n",
    "if X_apt is not None:\n",
    "    X_train_apt, X_test_apt, y_train_apt, y_test_apt = train_test_split(\n",
    "        X_apt, y_apt, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(f\" Appartements - Train: {len(X_train_apt)}, Test: {len(X_test_apt)}\")\n",
    "\n",
    "if X_maisons is not None:\n",
    "    X_train_maisons, X_test_maisons, y_train_maisons, y_test_maisons = train_test_split(\n",
    "        X_maisons, y_maisons, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(f\" Maisons - Train: {len(X_train_maisons)}, Test: {len(X_test_maisons)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a0a03",
   "metadata": {},
   "source": [
    "##  Corrèlations des variables avec le prix au m²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e2684",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\" Corrélations avec prix_m2:\")\n",
    "\n",
    "# Appartements\n",
    "if df_apt_clean is not None:\n",
    "    print(\" APPARTEMENTS:\")\n",
    "    numeric_cols = df_apt_clean.select_dtypes(include=[np.number])\n",
    "    print(numeric_cols.corr()['prix_m2'].sort_values(ascending=False))\n",
    "\n",
    "# Maisons  \n",
    "if df_maisons_clean is not None:\n",
    "    print(\" MAISONS:\")\n",
    "    numeric_cols = df_maisons_clean.select_dtypes(include=[np.number])\n",
    "    print(numeric_cols.corr()['prix_m2'].sort_values(ascending=False))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd321a2",
   "metadata": {},
   "source": [
    "## Standardisation (uniquement pour x ) et entrainement du modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bcc6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Pour les appartements\n",
    "if X_train_apt is not None:\n",
    "    scaler_apt = StandardScaler()\n",
    "    X_train_apt_scaled = scaler_apt.fit_transform(X_train_apt)\n",
    "    X_test_apt_scaled = scaler_apt.transform(X_test_apt)\n",
    "\n",
    "# Pour les maisons\n",
    "if X_train_maisons is not None:\n",
    "    scaler_maisons = StandardScaler()\n",
    "    X_train_maisons_scaled = scaler_maisons.fit_transform(X_train_maisons)\n",
    "    X_test_maisons_scaled = scaler_maisons.transform(X_test_maisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b2e252",
   "metadata": {},
   "source": [
    "## Modèle de régréssion linéaire \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c8e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(\"Régression Linéaire...\")\n",
    "\n",
    "# Pour les appartements\n",
    "if 'X_train_apt_scaled' in locals():\n",
    "    print(\" APPARTEMENTS\")\n",
    "    lr_apt = LinearRegression()\n",
    "    lr_apt.fit(X_train_apt_scaled, y_train_apt)  \n",
    "    y_pred_lr_apt = lr_apt.predict(X_test_apt_scaled)\n",
    "    mse_lr_apt = mean_squared_error(y_test_apt, y_pred_lr_apt)\n",
    "    rmse_lr_apt = np.sqrt(mse_lr_apt)\n",
    "    r2_lr_apt = r2_score(y_test_apt, y_pred_lr_apt)\n",
    "    print(f\"-MSE: {mse_lr_apt:.2f}\")\n",
    "    print(f\"-RMSE: {rmse_lr_apt:>12,.2f} €/m²\")\n",
    "    print(f\"-R²:   {r2_lr_apt:>12.3f}\")\n",
    "\n",
    "# Pour les maisons\n",
    "if 'X_train_maisons_scaled' in locals():\n",
    "    print(\" MAISONS\")\n",
    "    lr_maisons = LinearRegression()\n",
    "    lr_maisons.fit(X_train_maisons_scaled, y_train_maisons)  \n",
    "    y_pred_lr_maisons = lr_maisons.predict(X_test_maisons_scaled)\n",
    "\n",
    "    mse_lr_maisons = mean_squared_error(y_test_maisons, y_pred_lr_maisons)\n",
    "    rmse_lr_maisons = np.sqrt(mse_lr_maisons)\n",
    "    r2_lr_maisons = r2_score(y_test_maisons, y_pred_lr_maisons)\n",
    "    print(f\"-MSE: {mse_lr_maisons:.2f}\")\n",
    "    print(f\"-RMSE: {rmse_lr_maisons:>12,.2f} €/m²\")\n",
    "    print(f\"-R²:   {r2_lr_maisons:>12.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf1add6",
   "metadata": {},
   "source": [
    "## Modèle décision threeregressor avec hyper-paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aff62a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DECISION TREE REGRESSOR\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "print(\" DECISION TREE REGRESSOR\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Pour les appartements\n",
    "if 'X_train_apt_scaled' in locals():\n",
    "    print(\" APPARTEMENTS - Decision Tree\")\n",
    "    dt_apt = DecisionTreeRegressor(\n",
    "        random_state=42,    # ramdom state fix \n",
    "        max_depth=10,       # limite de profondeur\n",
    "        min_samples_split=5,# minimun d'échantillon pour la division\n",
    "        min_samples_leaf=2) # minimun d'échantillon /feuille \n",
    "    dt_apt.fit(X_train_apt_scaled, y_train_apt)\n",
    "    y_pred_dt_apt = dt_apt.predict(X_test_apt_scaled)\n",
    "\n",
    "    #calcul des metrics \n",
    "    mse_dt_apt = mean_squared_error(y_test_apt, y_pred_dt_apt)\n",
    "    rmse_dt_apt = np.sqrt(mse_dt_apt)\n",
    "    r2_dt_apt = r2_score(y_test_apt, y_pred_dt_apt)\n",
    "    print(f\"-MSE:  {mse_dt_apt:>12,.2f}\")\n",
    "    print(f\"-RMSE: {rmse_dt_apt:>12,.2f} €/m²\")\n",
    "    print(f\"-R²:   {r2_dt_apt:>12.3f}\")\n",
    "\n",
    "# Pour les maisons\n",
    "if 'X_train_maisons_scaled' in locals():\n",
    "    print(\" MAISONS - Decision Tree\")\n",
    "    dt_maisons = DecisionTreeRegressor(\n",
    "        random_state=42,     # ramdom state fix \n",
    "        max_depth=10,        # # Limite de profondeur\n",
    "        min_samples_split=5, # Minimun d'échantillon pour la division\n",
    "        min_samples_leaf=2   # Minimum d'échantillons / feuille\n",
    "    )\n",
    "    dt_maisons.fit(X_train_maisons_scaled, y_train_maisons)\n",
    "    y_pred_dt_maisons = dt_maisons.predict(X_test_maisons_scaled)\n",
    "\n",
    "    #calcul des metrics\n",
    "    mse_dt_maisons = mean_squared_error(y_test_maisons, y_pred_dt_maisons)\n",
    "    rmse_dt_maisons = np.sqrt(mse_dt_maisons)\n",
    "    r2_dt_maisons = r2_score(y_test_maisons, y_pred_dt_maisons)\n",
    "    \n",
    "    #affichage des metrcis avec formatage \n",
    "    print(f\"-MSE: {mse_dt_maisons:>12,.2f}\")\n",
    "    print(f\"-RMSE: {rmse_dt_maisons:>12,.2f} €/m²\")\n",
    "    print(f\"-R²:   {r2_dt_maisons:>12.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79e501c",
   "metadata": {},
   "source": [
    "## Modèle ramdom forest avec hyper-paramètres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6323fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "print(\"\\n RANDOM FOREST REGRESSOR\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Pour les appartements\n",
    "if 'X_train_apt_scaled' in locals():\n",
    "    print(\" APPARTEMENTS - Random Forest\")\n",
    "    rf_apt = RandomForestRegressor(n_estimators=50, random_state=42)    # radomstate fix pour la reprodubilité \n",
    "    rf_apt.fit(X_train_apt_scaled, y_train_apt)\n",
    "    y_pred_rf_apt = rf_apt.predict(X_test_apt_scaled)\n",
    "    \n",
    "    # Calcul des métrics \n",
    "    mse_rf_apt = mean_squared_error(y_test_apt, y_pred_rf_apt)\n",
    "    rmse_rf_apt = np.sqrt(mse_dt_apt)\n",
    "    r2_rf_apt = r2_score(y_test_apt, y_pred_rf_apt)\n",
    "    print(f\"-MSE: {mse_rf_apt:.2f}\")\n",
    "    print(f\"-RMSE: {rmse_rf_apt:>12,.2f} €/m²\")\n",
    "    print(f\"-R²:   {r2_rf_apt:>12.3f}\")\n",
    "\n",
    "\n",
    "# Pour les maisons\n",
    "if 'X_train_maisons_scaled' in locals():\n",
    "    print(\"MAISONS - Random Forest\")\n",
    "    rf_maisons = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "    rf_maisons.fit(X_train_maisons_scaled, y_train_maisons)\n",
    "    y_pred_rf_maisons = rf_maisons.predict(X_test_maisons_scaled)\n",
    "\n",
    "    # Calcul des métrics \n",
    "    mse_rf_maisons = mean_squared_error(y_test_maisons, y_pred_rf_maisons)\n",
    "    rmse_rf_maisons = np.sqrt(mse_rf_maisons)\n",
    "    r2_rf_maisons = r2_score(y_test_maisons, y_pred_rf_maisons)\n",
    "    print(f\"-MSE: {mse_rf_maisons:.2f}\")\n",
    "    print(f\"-RMSE: {rmse_rf_maisons:>12,.2f} €/m²\")\n",
    "    print(f\"-R²:   {r2_rf_maisons:>12.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec1f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "print(\" OPTIMISATION AVEC GRIDSEARCHCV\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# OPTIMISATION DECISION TREE\n",
    "\n",
    "\n",
    "print(\"\\n OPTIMISATION DECISION TREE\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Paramètres à tester pour Decision Tree\n",
    "dt_params = {\n",
    "    'max_depth': [5, 8, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_impurity_decrease': [0.0, 0.01]\n",
    "}\n",
    "\n",
    "# Pour les appartements\n",
    "if 'X_train_apt_scaled' in locals():\n",
    "    print(\" APPARTEMENTS - Decision Tree GridSearch\")\n",
    "    \n",
    "    dt_grid_apt = GridSearchCV(\n",
    "        DecisionTreeRegressor(random_state=42),\n",
    "        dt_params,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    dt_grid_apt.fit(X_train_apt_scaled, y_train_apt)\n",
    "    \n",
    "    # Prédictions avec le meilleur modèle\n",
    "    y_pred_dt_opt_apt = dt_grid_apt.predict(X_test_apt_scaled)\n",
    "    \n",
    "    # Métriques\n",
    "    mse_dt_opt_apt = mean_squared_error(y_test_apt, y_pred_dt_opt_apt)\n",
    "    rmse_dt_opt_apt = np.sqrt(mse_dt_opt_apt)\n",
    "    r2_dt_opt_apt = r2_score(y_test_apt, y_pred_dt_opt_apt)\n",
    "    \n",
    "    print(f\"   Meilleurs paramètres: {dt_grid_apt.best_params_}\")\n",
    "    print(f\"   MSE optimisé:  {mse_dt_opt_apt:>12,.2f}\")\n",
    "    print(f\"   RMSE optimisé: {rmse_dt_opt_apt:>12,.2f} €/m²\")\n",
    "    print(f\"   R² optimisé:   {r2_dt_opt_apt:>12.3f}\")\n",
    "\n",
    "# Pour les maisons\n",
    "if 'X_train_maisons_scaled' in locals():\n",
    "    print(\"\\n MAISONS - Decision Tree GridSearch\")\n",
    "    \n",
    "    dt_grid_maisons = GridSearchCV(\n",
    "        DecisionTreeRegressor(random_state=42),\n",
    "        dt_params,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    dt_grid_maisons.fit(X_train_maisons_scaled, y_train_maisons)\n",
    "    \n",
    "    # Prédictions avec le meilleur modèle\n",
    "    y_pred_dt_opt_maisons = dt_grid_maisons.predict(X_test_maisons_scaled)\n",
    "    \n",
    "    # Métriques\n",
    "    mse_dt_opt_maisons = mean_squared_error(y_test_maisons, y_pred_dt_opt_maisons)\n",
    "    rmse_dt_opt_maisons = np.sqrt(mse_dt_opt_maisons)\n",
    "    r2_dt_opt_maisons = r2_score(y_test_maisons, y_pred_dt_opt_maisons)\n",
    "    \n",
    "    print(f\"   Meilleurs paramètres: {dt_grid_maisons.best_params_}\")\n",
    "    print(f\"   MSE optimisé:  {mse_dt_opt_maisons:>12,.2f}\")\n",
    "    print(f\"   RMSE optimisé: {rmse_dt_opt_maisons:>12,.2f} €/m²\")\n",
    "    print(f\"   R² optimisé:   {r2_dt_opt_maisons:>12.3f}\")\n",
    "\n",
    "# OPTIMISATION RANDOM FOREST\n",
    "\n",
    "\n",
    "print(\"\\n OPTIMISATION RANDOM FOREST\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Paramètres à tester pour Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Pour les appartements\n",
    "if 'X_train_apt_scaled' in locals():\n",
    "    print(\" APPARTEMENTS - Random Forest GridSearch\")\n",
    "    \n",
    "    grid_rf_apt = GridSearchCV(\n",
    "        RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "        rf_params,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_rf_apt.fit(X_train_apt_scaled, y_train_apt)\n",
    "    \n",
    "    # Prédictions avec le meilleur modèle\n",
    "    y_pred_rf_opt_apt = grid_rf_apt.predict(X_test_apt_scaled)\n",
    "    \n",
    "    # Métriques\n",
    "    mse_rf_opt_apt = mean_squared_error(y_test_apt, y_pred_rf_opt_apt)\n",
    "    rmse_rf_opt_apt = np.sqrt(mse_rf_opt_apt)\n",
    "    r2_rf_opt_apt = r2_score(y_test_apt, y_pred_rf_opt_apt)\n",
    "    \n",
    "    print(f\"- Meilleurs paramètres: {grid_rf_apt.best_params_}\")\n",
    "    print(f\"- MSE optimisé:  {mse_rf_opt_apt:>12,.2f}\")\n",
    "    print(f\"- RMSE optimisé: {rmse_rf_opt_apt:>12,.2f} €/m²\")\n",
    "    print(f\"- R² optimisé:   {r2_rf_opt_apt:>12.3f}\")\n",
    "\n",
    "# Pour les maisons\n",
    "if 'X_train_maisons_scaled' in locals():\n",
    "    print(\"\\n MAISONS - Random Forest GridSearch\")\n",
    "    \n",
    "    dt_grid_maisons = GridSearchCV(\n",
    "        RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "        rf_params,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    dt_grid_maisons.fit(X_train_maisons_scaled, y_train_maisons)\n",
    "    \n",
    "    # Prédictions avec le meilleur modèle\n",
    "    y_pred_rf_opt_maisons = dt_grid_maisons.predict(X_test_maisons_scaled)\n",
    "    \n",
    "    # Métriques\n",
    "    mse_rf_opt_maisons = mean_squared_error(y_test_maisons, y_pred_rf_opt_maisons)\n",
    "    rmse_rf_opt_maisons = np.sqrt(mse_rf_opt_maisons)\n",
    "    r2_rf_opt_maisons = r2_score(y_test_maisons, y_pred_rf_opt_maisons)\n",
    "    \n",
    "    print(f\"   Meilleurs paramètres: {dt_grid_maisons.best_params_}\")\n",
    "    print(f\"   MSE optimisé:  {mse_rf_opt_maisons:>12,.2f}\")\n",
    "    print(f\"   RMSE optimisé: {rmse_rf_opt_maisons:>12,.2f} €/m²\")\n",
    "    print(f\"   R² optimisé:   {r2_rf_opt_maisons:>12.3f}\")\n",
    "\n",
    "print(\"\\n Optimisation GridSearchCV terminée !\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa84d1f",
   "metadata": {},
   "source": [
    "## Visualisation vraie valeur / prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48625a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualisation Appartements\n",
    "if 'y_pred_lr_apt' in locals():\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_test_apt, y_pred_lr_apt, alpha=0.6)  \n",
    "    plt.plot([y_test_apt.min(), y_test_apt.max()], \n",
    "             [y_test_apt.min(), y_test_apt.max()], \n",
    "             color=\"red\", linestyle=\"--\")\n",
    "    plt.xlabel(\"Vraies valeurs (€/m²)\")\n",
    "    plt.ylabel(\"Prédictions (€/m²)\")\n",
    "    plt.title(\"Appartements - Vraies valeurs vs Prédictions\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Visualisation Maisons\n",
    "if 'y_pred_lr_maisons' in locals():\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_test_maisons, y_pred_lr_maisons, alpha=0.6)  \n",
    "    plt.plot([y_test_maisons.min(), y_test_maisons.max()], \n",
    "             [y_test_maisons.min(), y_test_maisons.max()], \n",
    "             color=\"red\", linestyle=\"--\")\n",
    "    plt.xlabel(\"Vraies valeurs (€/m²)\")\n",
    "    plt.ylabel(\"Prédictions (€/m²)\")\n",
    "    plt.title(\"Maisons - Vraies valeurs vs Prédictions\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa57143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports et vérification XGBoost\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    import numpy as np\n",
    "    XGBOOST_AVAILABLE = True\n",
    "    print(\" XGBoost disponible\")\n",
    "except ImportError:\n",
    "    print(\" XGBoost non disponible. Installez avec: pip install xgboost\")\n",
    "    XGBOOST_AVAILABLE = False\n",
    "\n",
    "# XGBoost pour les appartements\n",
    "if XGBOOST_AVAILABLE and 'X_train_apt_scaled' in locals():\n",
    "    print(\" XGBoost APPARTEMENTS...\")\n",
    "    xgb_apt = XGBRegressor(random_state=42, eval_metric='rmse')\n",
    "    xgb_apt.fit(X_train_apt_scaled, y_train_apt) \n",
    "    y_pred_xgb_apt = xgb_apt.predict(X_test_apt_scaled)\n",
    "    mse_xgb_apt = mean_squared_error(y_test_apt, y_pred_xgb_apt)\n",
    "    rmse_xgb_apt = np.sqrt(mse_xgb_apt)\n",
    "    r2_xgb_apt = r2_score(y_test_apt, y_pred_xgb_apt)\n",
    "    \n",
    "    print(f\"   MSE:  {mse_xgb_apt:>12,.2f}\")\n",
    "    print(f\"   RMSE: {rmse_xgb_apt:>12,.2f} €/m²\")\n",
    "    print(f\"   R²:   {r2_xgb_apt:>12.3f}\")\n",
    "\n",
    "# XGBoost pour les maisons\n",
    "if XGBOOST_AVAILABLE and 'X_train_maisons_scaled' in locals():\n",
    "    print(\"\\n XGBoost MAISONS...\")\n",
    "    xgb_maisons = XGBRegressor(random_state=42, eval_metric='rmse')\n",
    "    xgb_maisons.fit(X_train_maisons_scaled, y_train_maisons) \n",
    "    y_pred_xgb_maisons = xgb_maisons.predict(X_test_maisons_scaled)\n",
    "    mse_xgb_maisons = mean_squared_error(y_test_maisons, y_pred_xgb_maisons)\n",
    "    rmse_xgb_maisons = np.sqrt(mse_xgb_maisons)\n",
    "    r2_xgb_maisons = r2_score(y_test_maisons, y_pred_xgb_maisons)\n",
    "    \n",
    "    print(f\"   MSE:  {mse_xgb_maisons:>12,.2f}\")\n",
    "    print(f\"   RMSE: {rmse_xgb_maisons:>12,.2f} €/m²\")\n",
    "    print(f\"   R²:   {r2_xgb_maisons:>12.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742d2ff",
   "metadata": {},
   "source": [
    "## Sauvegarde des modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "#  Extraire les meilleurs modèles depuis vos GridSearchCV\n",
    "best_model_apt = dt_grid_apt.best_estimator_\n",
    "best_model_maisons = dt_grid_maisons.best_estimator_\n",
    "\n",
    "print(f\"Meilleur modèle appartements: {type(best_model_apt).__name__}\")\n",
    "print(f\"Paramètres apt: {dt_grid_apt.best_params_}\")\n",
    "\n",
    "print(f\"Meilleur modèle maisons: {type(best_model_maisons).__name__}\")\n",
    "print(f\"Paramètres maisons: {dt_grid_maisons.best_params_}\")\n",
    "\n",
    "#  Sauvegarder les MEILLEURS modèles (pas les LinearRegression)\n",
    "joblib.dump(best_model_apt, '../models/lille_appartements.pkl')        # ← Random Forest optimisé\n",
    "joblib.dump(best_model_maisons, '../models/lille_maisons.pkl')         # ← Random Forest optimisé\n",
    "joblib.dump(scaler_apt, '../models/scaler_lille_apt.pkl')\n",
    "joblib.dump(scaler_maisons, '../models/scaler_lille_maisons.pkl')\n",
    "\n",
    "#  garder aussi les objets GridSearchCV complets\n",
    "joblib.dump(dt_grid_maisons, '../models/grid_lille_maisons.pkl')\n",
    "joblib.dump(dt_grid_apt, '../models/grid_lille_appartement.pkl')\n",
    "\n",
    "print(\" Modèles OPTIMISÉS sauvegardés (Random Forest)\")\n",
    "print(\" Scalers sauvegardés\")\n",
    "print(\" GridSearchCV complets sauvegardés\")\n",
    "\n",
    "#  Vérification\n",
    "print(f\"\\nModèle appartements sauvé: {type(best_model_apt).__name__}\")\n",
    "print(f\"Modèle maisons sauvé: {type(best_model_maisons).__name__}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
